{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/liuchentue/SVM-based-human-detection/blob/main/Faster_RCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BTmwaeejlFTV",
    "outputId": "3c72644b-743a-44bc-e49f-9089b9603d59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/cu101/torch_stable.html\n",
      "Requirement already up-to-date: torch==1.5 in c:\\users\\admin\\anaconda3\\lib\\site-packages (1.5.0+cu101)\n",
      "Requirement already up-to-date: torchvision==0.6 in c:\\users\\admin\\anaconda3\\lib\\site-packages (0.6.0+cu101)\n",
      "Requirement already satisfied, skipping upgrade: numpy in c:\\users\\admin\\anaconda3\\lib\\site-packages (from torch==1.5) (1.16.5)\n",
      "Requirement already satisfied, skipping upgrade: future in c:\\users\\admin\\anaconda3\\lib\\site-packages (from torch==1.5) (0.17.1)\n",
      "Requirement already satisfied, skipping upgrade: pillow>=4.1.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from torchvision==0.6) (6.2.0)\n",
      "Requirement already satisfied: cython in c:\\users\\admin\\anaconda3\\lib\\site-packages (0.29.13)\n",
      "Collecting pyyaml==5.1\n",
      "  Using cached https://files.pythonhosted.org/packages/b6/74/c3e15707516f80192059dde32c9d78f00a88c9f3c4d1efd76cbc8d5b0a20/PyYAML-5.1-cp37-cp37m-win_amd64.whl\n",
      "Installing collected packages: pyyaml\n",
      "  Found existing installation: PyYAML 5.1.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Cannot uninstall 'PyYAML'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.\n",
      "ERROR: Invalid requirement: \"'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\"\n",
      "Hint: = is not a valid operator. Did you mean == ?\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[WinError 126] The specified module could not be found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-5b0546c4f313>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pip install cython pyyaml==5.1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'gcc --version'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[0mdlls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mth_dll_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'*.dll'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mdll\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdlls\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m         \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdll\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\ctypes\\__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, handle, use_errno, use_last_error)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 364\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    365\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 126] The specified module could not be found"
     ]
    }
   ],
   "source": [
    "# install dependencies: \n",
    "!pip install -U torch==1.5 torchvision==0.6 -f https://download.pytorch.org/whl/cu101/torch_stable.html\n",
    "!pip install cython pyyaml==5.1\n",
    "!pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n",
    "import torch, torchvision\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "!gcc --version\n",
    "# install detectron2:\n",
    "!pip install detectron2==0.1.3 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.5/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OehaD_dnykwY",
    "outputId": "03d214c9-ca6b-4846-a464-47a634ab0967"
   },
   "outputs": [],
   "source": [
    "# import some common detectron2 utilities\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "import cv2\n",
    "\n",
    "# get image\n",
    "!wget http://images.cocodataset.org/val2017/000000439715.jpg -O input.jpg\n",
    "im = cv2.imread(\"./input.jpg\")\n",
    "\n",
    "# Create config\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(\"/usr/local/lib/python3.6/dist-packages/detectron2/model_zoo/configs/COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\")\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model\n",
    "cfg.MODEL.WEIGHTS = \"detectron2://COCO-Detection/faster_rcnn_R_101_FPN_3x/137851257/model_final_f6e8b1.pkl\"\n",
    "\n",
    "# Create predictor\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "# Make prediction\n",
    "outputs = predictor(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 593
    },
    "id": "JYeCP2PK2YTZ",
    "outputId": "db9eefb3-4b74-4dcd-d268-0494e414f1d0"
   },
   "outputs": [],
   "source": [
    "from google.colab.patches import cv2_imshow\n",
    "v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
    "v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "cv2_imshow(v.get_image()[:, :, ::-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qh0ZbRc1q6cO",
    "outputId": "30539daa-837e-4516-edd0-63a2104ef0f9"
   },
   "outputs": [],
   "source": [
    "#Function for counting the number of people present in the image\n",
    "def CountPerson(img):\n",
    "  # Create predictor\n",
    "  predictor = DefaultPredictor(cfg)\n",
    "  # Make prediction\n",
    "  outputs = predictor(img)\n",
    "  inst=outputs[\"instances\"]\n",
    "  #extract the information from the predictor outputs\n",
    "  classes=inst.get(\"pred_classes\")\n",
    "  precision=inst.get(\"scores\")\n",
    "  locations=inst.get(\"pred_boxes\")\n",
    "  #classes: what type of object is detected (for example, 0 for person; 25 for umbrella; 17 for horse) (based on COCO dataset)\n",
    "  #locations: the boxes locations of the detected objects (in our case, there are 17 boxes in the example photo)\n",
    "  #precision: the probability of the corresponding object classification to be accurate\n",
    "  classes=tf.make_ndarray(tf.make_tensor_proto(classes.cpu())) \n",
    "  precision=tf.make_ndarray(tf.make_tensor_proto(precision.cpu())) \n",
    "  locations=tf.make_ndarray(tf.make_tensor_proto(locations.tensor.cpu()))\n",
    "  numofperson=0\n",
    "  for i in range(len(classes)):\n",
    "    if (classes[i]==0):\n",
    "      numofperson=numofperson+1\n",
    "  print(\"Number of people in the picture:\",numofperson)\n",
    "\n",
    "\n",
    "#Example showing how to use this function with the sample image\n",
    "CountPerson(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gRP4pi9GoXYO",
    "outputId": "ced78818-0424-49a6-bea2-642c8d3e006f"
   },
   "outputs": [],
   "source": [
    " #Function for extracting the person boxes out from the image using the Faster RCNN\n",
    "def Identifyperson(img, personlist): \n",
    "  # Create predictor\n",
    "  predictor = DefaultPredictor(cfg)\n",
    "  # Make prediction\n",
    "  outputs = predictor(img)\n",
    "  inst=outputs[\"instances\"]\n",
    "  #extract the information from the predictor outputs\n",
    "  classes=inst.get(\"pred_classes\")\n",
    "  precision=inst.get(\"scores\")\n",
    "  locations=inst.get(\"pred_boxes\")\n",
    "  #classes: what type of object is detected (for example, 0 for person; 25 for umbrella; 17 for horse) (based on COCO dataset)\n",
    "  #locations: the boxes locations of the detected objects (in our case, there are 17 boxes in the example photo)\n",
    "  #precision: the probability of the corresponding object classification to be accurate\n",
    "  classes=tf.make_ndarray(tf.make_tensor_proto(classes.cpu())) \n",
    "  precision=tf.make_ndarray(tf.make_tensor_proto(precision.cpu())) \n",
    "  locations=tf.make_ndarray(tf.make_tensor_proto(locations.tensor.cpu()))\n",
    "  #append the boxes that are predicted to be person into the output list\n",
    "  for i in range (len(classes)):\n",
    "    if(classes[i]==0):\n",
    "      personlist.append(locations[i])\n",
    "\n",
    "\n",
    "#Example showing how to use this function with the sample image\n",
    "personboxes=[]\n",
    "Identifyperson(im,personboxes)\n",
    "print(personboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uev6Ed42fM2A"
   },
   "outputs": [],
   "source": [
    "#functions for cropping the person boxes as indicated by the locations and display them\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_gallery(images, h, w, n_row=1,n_col=6):\n",
    "    \"\"\"Helper function to plot a gallery of portraits\"\"\"\n",
    "    plt.figure(figsize=(1.8 * n_col, 2.4 * n_row))\n",
    "    plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)\n",
    "    for i in range(n_row * n_col):\n",
    "        plt.subplot(n_row, n_col, i + 1)\n",
    "        plt.imshow(cv2.cvtColor(images[i],cv2.COLOR_BGR2RGB))\n",
    "        print(np.shape(images[i]))\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())\n",
    "\n",
    "def cropboxes(testim, bx,personset):\n",
    "  for i in range(len(bx)):\n",
    "    bxi=bx[i]\n",
    "    y1=int(bxi[0])\n",
    "    y2=int(bxi[2])\n",
    "    x1=int(bxi[1])\n",
    "    x2=int(bxi[3])\n",
    "    personi=testim[x1:x2,y1:y2]\n",
    "    personset.append(personi)\n",
    " # plot_gallery(personset,100,30)  \n",
    "\n",
    "\n",
    "#showing an example of cropping using the sample image\n",
    "personimgs= []\n",
    "cropboxes(im,personboxes,personimgs)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 710
    },
    "id": "yxQ5Eiym4qn8",
    "outputId": "e4f62d53-7527-4d75-d54e-877531282b44"
   },
   "outputs": [],
   "source": [
    "# to clear directory\n",
    "#!rm -rf SVM-based-human-detection\n",
    "\n",
    "# to clone directory, -b for specific branch\n",
    "!git clone -b mtk3-loading-images https://github.com/liuchentue/SVM-based-human-detection.git\n",
    "\n",
    "img0001 = cv2.imread(\"SVM-based-human-detection/frames/seq_000001.jpg\")\n",
    "\n",
    "\n",
    "\n",
    "# Make prediction\n",
    "outputs = predictor(img0001)\n",
    "\n",
    "v = Visualizer(img0001[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
    "out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "cv2_imshow(out.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U7HxX2QftHc1"
   },
   "outputs": [],
   "source": [
    "# All images written into list  images\n",
    "import sys, os, glob\n",
    "images = [cv2.imread(file) for file in sorted(glob.glob(\"SVM-based-human-detection/frames/*.jpg\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4-LgpKaBu4Ry",
    "outputId": "627b2f56-bf74-493f-f483-f181bf8c7db7"
   },
   "outputs": [],
   "source": [
    "# Part1 is finished here\n",
    "for i in range (50):\n",
    "  print(\"Image seq_\",i+1)\n",
    "  CountPerson(images[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "id": "R573Aqkk2XIH",
    "outputId": "e07a245c-9f90-41d2-d4ce-357b3e7c29b0"
   },
   "outputs": [],
   "source": [
    "person_dataset=[]\n",
    "for i in range (100):\n",
    "  pb=[]\n",
    "  Identifyperson(images[i],pb)\n",
    "  cropboxes(images[i],pb,person_dataset)\n",
    "\n",
    "print(len(person_dataset))\n",
    "cv2_imshow(person_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPDKe1iRKg2YohZlX/qMAIF",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Faster_RCNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
